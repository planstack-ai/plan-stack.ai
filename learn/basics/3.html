<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Why Accuracy Drops with Length - Basics #3 - Plan Stack</title>
    <meta name="description" content="Understanding why longer context means lower accuracy. The 'Lost in the Middle' problem explained simply.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Space+Grotesk:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../styles/common.css">
    <link rel="stylesheet" href="../styles/lesson.css">
</head>
<body>
<header>
    <div class="container">
        <a href="../../" class="logo">
            <div class="logo-icon">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5"><path d="M4 6h16M4 12h16M4 18h10" stroke="#000"/></svg>
            </div>
            Plan Stack
        </a>
        <nav class="nav-links">
            <a href="https://github.com/planstack-ai/planstack/blob/main/docs/getting-started.md">Docs</a>
            <a href="../" class="active">Learn</a>
            <a href="../../articles/">Blog</a>
            <a href="https://github.com/planstack-ai/planstack" class="btn btn-secondary">
                <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                GitHub
            </a>
        </nav>
    </div>
</header>

<main>
    <article class="lesson-container">
        <div class="lesson-meta">
            <span class="lesson-badge">Basics</span>
            <span class="lesson-number">Lesson 3 of 5</span>
        </div>

        <h1 class="lesson-title">Why Accuracy Drops with Length</h1>

        <div class="lesson-content">
            <p>
                "I gave Claude all the context it needed, but it still ignored the important part."
                This is one of the most common frustrations. You carefully include the relevant code,
                but Claude's response misses a critical detail that was right there in the middle.
            </p>

            <p>
                This isn't a bug. <strong>It's how attention works.</strong>
            </p>

            <h2>Lost in the Middle</h2>

            <p>
                Research has shown that LLMs pay unequal attention across long contexts.
                They focus heavily on the <strong>beginning</strong> and <strong>end</strong>,
                while information in the <strong>middle gets forgotten</strong>.
            </p>

            <div class="attention-diagram">
                <h3>Attention Distribution Across Context</h3>
                <div class="attention-bar">
                    <div class="attention-segment"></div>
                    <div class="attention-segment"></div>
                    <div class="attention-segment"></div>
                    <div class="attention-segment"></div>
                    <div class="attention-segment"></div>
                    <div class="attention-segment"></div>
                    <div class="attention-segment"></div>
                    <div class="attention-segment"></div>
                    <div class="attention-segment"></div>
                </div>
                <div class="attention-labels">
                    <span>Start (high attention)</span>
                    <span>Middle (low attention)</span>
                    <span>End (high attention)</span>
                </div>
            </div>

            <p>
                Think about how you read a long book. You remember the opening clearly.
                You remember the ending. But chapter 17? That's fuzzy. LLMs have the same pattern,
                just more pronounced.
            </p>

            <h2>The Human Parallel</h2>

            <p>
                Imagine someone reads you a list of 100 items, then asks which items were mentioned.
                You'd probably remember the first few and the last few, but struggle with the middle.
                That's not a failure of memory—it's how attention naturally works.
            </p>

            <div class="callout">
                <p>
                    Claude can <em>access</em> everything in context. But accessing and <em>paying attention to</em>
                    are different things. Just because information is there doesn't mean it will influence the response.
                </p>
            </div>

            <h2>Practical Implications</h2>

            <p>This has real consequences for how you structure prompts:</p>

            <ul>
                <li><strong>Put important information at the start or end</strong> of your prompt</li>
                <li><strong>Don't bury critical details</strong> in the middle of long code blocks</li>
                <li><strong>Shorter context = more even attention</strong> across everything</li>
                <li><strong>Repeat key requirements</strong> at the end if context is long</li>
            </ul>

            <h2>The Implication</h2>

            <p>
                This is why "just dump everything in" fails. More context doesn't just waste tokens—it
                actively dilutes attention. The important 500 tokens get lost among 50,000 irrelevant ones.
            </p>

            <div class="callout warning">
                <p>
                    <strong>Shorter is not just more efficient. Shorter is more accurate.</strong>
                    A focused 5K token context often outperforms a comprehensive 50K token context.
                </p>
            </div>

            <div class="key-takeaway">
                <h3>Key Takeaways</h3>
                <ul>
                    <li>Attention is uneven: start and end get more focus than middle</li>
                    <li>Information in the middle of long contexts gets systematically ignored</li>
                    <li>Put critical information at the beginning or end of your prompt</li>
                    <li>Shorter context = more accurate results (less gets "lost")</li>
                </ul>
            </div>
        </div>

        <nav class="lesson-nav">
            <a href="./2.html" class="lesson-nav-btn">← Previous</a>
            <div class="progress-dots">
                <span class="progress-dot completed"></span>
                <span class="progress-dot completed"></span>
                <span class="progress-dot active"></span>
                <span class="progress-dot"></span>
                <span class="progress-dot"></span>
            </div>
            <a href="./4.html" class="lesson-nav-btn primary">Next: Context Design →</a>
        </nav>
    </article>
</main>

<footer>
    <div class="container">
        <p>Created by <a href="https://x-hack.jp">X-HACK Inc.</a> | MIT License</p>
        <div class="footer-links">
            <a href="https://github.com/planstack-ai/planstack">GitHub</a>
            <a href="../">Learn</a>
            <a href="../../articles/">Blog</a>
        </div>
    </div>
</footer>
</body>
</html>
